{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_tfl_json\n",
    "import google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from mylibrary.connections import cursor, conn, engine, Automapped_Base, session\n",
    "\n",
    "sql = \"\"\"\n",
    "select * from tt_h.stations_journeytime as sjt\n",
    "where tfl_message = 'ok' and\n",
    " sjt.icscode not in (select icscode from tt_h.all_stations where in_sprawl = true) and \n",
    " sjt.icscode in (select icscode from tt_h.all_stations where lat < 53.39926695813 and lng > -2.54)\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_journeys import get_station_lat_lng_from_icscode, get_london_icscodes, add_cycle_and_total_time, remove_journeys_not_arriving_clondon\n",
    "from google import get_cycle_info\n",
    "import parse_tfl_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df.iterrows():\n",
    "    index = r[0]\n",
    "    row = r[1]\n",
    "    \n",
    "    lat, lng = get_station_lat_lng_from_icscode(row[\"icscode\"])\n",
    "\n",
    "    df.loc[index, \"depart_lat\"] = lat\n",
    "    df.loc[index, \"depart_lng\"] = lng\n",
    "    \n",
    "    try:\n",
    "        j1 = row[\"tfl_response\"]\n",
    "        j2 = json.loads(j1)\n",
    "    except:\n",
    "        print(\"parse problem\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        journeys = j2[\"journeys\"]\n",
    "    except:\n",
    "        print(\"no journeys in json\")\n",
    "        continue\n",
    "    \n",
    "    # Fill in journey summary so it exists even for journeys that don't end in central london\n",
    "    journey = journeys[0]\n",
    "    legs = journey[\"legs\"]\n",
    "    summary = parse_tfl_json.summarise_legs(legs)\n",
    "    df.loc[index, \"natrail_journey_summary\"] = summary\n",
    "    \n",
    "    for journey in journeys:\n",
    "        legs = journey[\"legs\"]\n",
    "        journey[\"legs\"] = parse_tfl_json.remove_non_national_rail(legs)\n",
    "    \n",
    "    # Keep only journeys with a national rail component\n",
    "    journeys = [j for j in journeys if len(j[\"legs\"]) > 0]\n",
    "\n",
    "    # Keep only journeys that end in central London  \n",
    "    try:\n",
    "        journeys = remove_journeys_not_arriving_clondon(journeys)\n",
    "    except:\n",
    "        print(\"Problem with journey starting at {}\".format(row[\"station_name\"]))\n",
    "        continue\n",
    "\n",
    "    \n",
    "    if len(journeys) == 0:\n",
    "        continue\n",
    "\n",
    "    journeys = add_cycle_and_total_time(journeys, row[\"tfl_dest\"])\n",
    "\n",
    "    journeys = sorted(journeys, key = lambda x: x[\"total_time\"])\n",
    "\n",
    "    journey = journeys[0]\n",
    "    legs = journey[\"legs\"]\n",
    "\n",
    "    summary = parse_tfl_json.summarise_legs(legs)\n",
    "    df.loc[index, \"natrail_journey_summary\"] = summary\n",
    "\n",
    "    df.loc[index, \"natrail_train_changes\"] = parse_tfl_json.num_changes(legs)\n",
    "    df.loc[index, \"final_arrival\"] = parse_tfl_json.final_arrival(legs)\n",
    "\n",
    "    travel_time_minutes = parse_tfl_json.get_total_travel_time(legs) \n",
    "    df.loc[index, \"natrail_journey_minutes\"] = travel_time_minutes\n",
    "\n",
    "    lat_lng = parse_tfl_json.lat_lng_from_legs(legs)\n",
    "    \n",
    "    \n",
    "    df.loc[index, \"arrive_lat\"] = lat_lng[\"arrive\"][\"lat\"]\n",
    "    df.loc[index, \"arrive_lng\"] = lat_lng[\"arrive\"][\"lng\"]\n",
    "\n",
    "    df.loc[index, \"cycle_minutes\"] = journey[\"cycle_minutes\"]\n",
    "    df.loc[index, \"cycle_miles\"] = journey[\"cycle_miles\"]\n",
    "    df.loc[index, \"total_journeytime\"] = journey[\"cycle_minutes\"] + travel_time_minutes\n",
    "\n",
    "    \n",
    "    \n",
    "cols = [c for c in df.columns if c not in [\"id\", \"tfl_request\", \"tfl_response\", \"querydict\"]]\n",
    "df2 = df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.sort_values([\"station_name\", \"tfl_dest\", \"total_journeytime\"]).drop_duplicates([\"station_name\", \"tfl_dest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_sql(\"parsed_rail_journeys\", engine, schema=\"tt_h\", if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "ALTER TABLE tt_h.parsed_rail_journeys ADD COLUMN id SERIAL PRIMARY KEY;\n",
    "\"\"\"\n",
    "cursor.execute(sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "# import json\n",
    "\n",
    "# counter = 0\n",
    "# for r in df3.iterrows():\n",
    "    \n",
    "#     index = r[0]\n",
    "#     row = r[1]\n",
    "\n",
    "#     if pd.notnull(row.natrail_journey_minutes):\n",
    "#         continue\n",
    "    \n",
    "#     counter += 1\n",
    "#     print(counter)\n",
    "#     depart_icscode = row[\"icscode\"]\n",
    "\n",
    "#     sql = \"\"\"\n",
    "#     select * from tt_h.anomalies_central_london_station\n",
    "#     where icscode_depart = '{}'\n",
    "#     \"\"\"\n",
    "\n",
    "#     df = pd.read_sql(sql.format(row[\"icscode\"]), conn)\n",
    "#     arrival_icscode = df.loc[0, \"arrival_icscode\"]\n",
    "\n",
    "#     attempts = utils.get_attempt(arrival_icscode, [\"0800\",\"0820\", \"0840\"], [\"20170817\",\"20170906\",\"20170908\"])\n",
    "#     for a in attempts:\n",
    "#         a[\"from\"] = depart_icscode\n",
    "\n",
    "#     from mylibrary.tfl_helpers import get_journeyplanner_results\n",
    "#     jny = get_journeyplanner_results(attempts)\n",
    "#     journeys = json.loads(jny[\"tfl_response\"])[\"journeys\"]\n",
    "    \n",
    "#     for journey in journeys:\n",
    "#         legs = journey[\"legs\"]\n",
    "#         journey[\"legs\"] = parse_tfl_json.remove_non_national_rail(legs)\n",
    "        \n",
    "#     journeys = remove_journeys_not_arriving_clondon(journeys)\n",
    "#     journeys = add_cycle_and_total_time(journeys, row[\"tfl_dest\"])\n",
    "#     journeys = sorted(journeys, key = lambda x: x[\"total_time\"])\n",
    "    \n",
    "#     journey = journeys[0]\n",
    "#     legs = journey[\"legs\"]\n",
    "\n",
    "#     summary = parse_tfl_json.summarise_legs(legs)\n",
    "#     df3.loc[index, \"natrail_journey_summary\"] = summary\n",
    "\n",
    "#     df3.loc[index, \"natrail_train_changes\"] = parse_tfl_json.num_changes(legs)\n",
    "#     df3.loc[index, \"final_arrival\"] = parse_tfl_json.final_arrival(legs)\n",
    "\n",
    "#     travel_time_minutes = parse_tfl_json.get_total_travel_time(legs) \n",
    "#     df3.loc[index, \"natrail_journey_minutes\"] = travel_time_minutes\n",
    "\n",
    "#     lat_lng = parse_tfl_json.lat_lng_from_legs(legs)\n",
    "    \n",
    "    \n",
    "#     df3.loc[index, \"arrive_lat\"] = lat_lng[\"arrive\"][\"lat\"]\n",
    "#     df3.loc[index, \"arrive_lng\"] = lat_lng[\"arrive\"][\"lng\"]\n",
    "\n",
    "#     df3.loc[index, \"cycle_minutes\"] = journey[\"cycle_minutes\"]\n",
    "#     df3.loc[index, \"cycle_miles\"] = journey[\"cycle_miles\"]\n",
    "#     df3.loc[index, \"total_journeytime\"] = journey[\"cycle_minutes\"] + travel_time_minutes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What follows should go in a data manipulation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf = df3[df3[\"tfl_dest\"] == \"SW1H9AJ\"]\n",
    "df_cw = df3[df3[\"tfl_dest\"] == \"E145HP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data = df_pf.merge(df_cw, how='left', on=[\"nlc\", \"icscode\", \"station_name\", \"tfl_message\", \"depart_lat\", \"depart_lng\"], suffixes=(\"_pf\", \"_cw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out to Postgres\n",
    "all_stations_data.to_sql(\"stations_maps_data\", engine, schema=\"tt_h\", if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data.to_csv(\"stations_maps_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data.rename(columns={\"depart_lat\":\"lat\", \"depart_lng\":\"lng\"}, inplace=True)\n",
    "all_stations_data.to_csv(\"interactive_maps_template/data/stations_maps_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on with e.g. newport?\n",
    "# df3[df3[\"icscode\"] == \"1000647\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf[df_pf.station_name.str.contains(\"udley\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
